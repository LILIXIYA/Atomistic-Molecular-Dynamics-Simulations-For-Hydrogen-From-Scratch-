{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5901f883",
      "metadata": {
        "id": "5901f883"
      },
      "source": [
        "# Colab setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b49f67",
      "metadata": {
        "id": "a7b49f67"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install pytorch-lifestream\n",
        "    !wget https://raw.githubusercontent.com/Matteus1904/GPT-like_approach_for_event_sequences/master/models.py\n",
        "    !wget https://raw.githubusercontent.com/Matteus1904/GPT-like_approach_for_event_sequences/master/dataset.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7431993",
      "metadata": {
        "id": "a7431993"
      },
      "source": [
        "## Data load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! curl -OL https://storage.googleapis.com/di-datasets/age-prediction-nti-sbebank-2019.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "9Dn2GC_QuQHo",
        "outputId": "858e642a-2686-4102-da1b-d7e0110f4960"
      },
      "id": "9Dn2GC_QuQHo",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (ipython-input-3917471108.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3917471108.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    curl -OL https://storage.googleapis.com/di-datasets/age-prediction-nti-sbebank-2019.zip\u001b[0m\n\u001b[0m                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "86d984d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86d984d6",
        "outputId": "4d858c2d-5a9d-45a2-c134-eada004b864d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   242  100   242    0     0    263      0 --:--:-- --:--:-- --:--:--   263\n",
            "Archive:  age-prediction-nti-sbebank-2019.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of age-prediction-nti-sbebank-2019.zip or\n",
            "        age-prediction-nti-sbebank-2019.zip.zip, and cannot find age-prediction-nti-sbebank-2019.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "! mkdir -p results\n",
        "\n",
        "if not os.path.exists('data/sberbank/transactions_train.csv'):\n",
        "    ! mkdir -p data\n",
        "    ! curl -OL https://storage.yandexcloud.net/di-datasets/age-prediction-nti-sbebank-2019.zip\n",
        "    ! unzip -j -o age-prediction-nti-sbebank-2019.zip 'data/*.csv' -d data/sberbank\n",
        "    ! mv age-prediction-nti-sbebank-2019.zip data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e91a902",
      "metadata": {
        "id": "9e91a902"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587df1ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:04.590559Z",
          "iopub.status.busy": "2022-05-04T18:11:04.590097Z",
          "iopub.status.idle": "2022-05-04T18:11:06.256016Z",
          "shell.execute_reply": "2022-05-04T18:11:06.255464Z"
        },
        "id": "587df1ea"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from models import GptPretrainContrastiveModule, NextItemPredictionModule\n",
        "\n",
        "from ptls.nn import TrxEncoder, RnnEncoder\n",
        "from ptls.frames.gpt import GptPretrainModule, GptDataset\n",
        "from ptls.preprocessing import PandasDataPreprocessor\n",
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.frames import PtlsDataModule\n",
        "\n",
        "from dataset import MlmNoSliceDataset\n",
        "\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82f989bc",
      "metadata": {
        "id": "82f989bc"
      },
      "source": [
        "## Data preproccessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e06bd27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:06.260046Z",
          "iopub.status.busy": "2022-05-04T18:11:06.259544Z",
          "iopub.status.idle": "2022-05-04T18:11:12.319460Z",
          "shell.execute_reply": "2022-05-04T18:11:12.317693Z"
        },
        "id": "7e06bd27",
        "outputId": "b070264a-4f29-4087-9214-6f5bf34af76f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>TRDATETIME</th>\n",
              "      <th>small_group</th>\n",
              "      <th>amount_rur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5201569</th>\n",
              "      <td>44379</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>62.535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2788175</th>\n",
              "      <td>43594</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>10.524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2788174</th>\n",
              "      <td>43594</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>86.255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18975203</th>\n",
              "      <td>5882</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>5.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18975202</th>\n",
              "      <td>5882</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>11.678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          client_id  TRDATETIME  small_group  amount_rur\n",
              "5201569       44379           0           52      62.535\n",
              "2788175       43594           0          125      10.524\n",
              "2788174       43594           0           36      86.255\n",
              "18975203       5882           0           12       5.132\n",
              "18975202       5882           0           18      11.678"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_path = 'data/sberbank'\n",
        "\n",
        "\n",
        "source_data = pd.read_csv(os.path.join(data_path, 'transactions_train.csv'))\n",
        "source_data = source_data.rename({'trans_date': 'TRDATETIME'}, axis=1)\n",
        "source_data = source_data.sort_values(by=['TRDATETIME'])\n",
        "source_data = source_data.rename(columns={'cl_id':'client_id', 'MCC':'small_group', 'amount':'amount_rur'})\n",
        "source_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6735f933",
      "metadata": {
        "id": "6735f933"
      },
      "outputs": [],
      "source": [
        "mcc_to_id = {mcc: i+1 for i, mcc in enumerate(source_data['small_group'].unique())}\n",
        "\n",
        "source_data['amount_rur_bin'] = 1 + KBinsDiscretizer(10, encode='ordinal', subsample=None).fit_transform(source_data[['amount_rur']]).astype('int')\n",
        "source_data['small_group'] = source_data['small_group'].map(mcc_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8615b722",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:12.324005Z",
          "iopub.status.busy": "2022-05-04T18:11:12.323387Z",
          "iopub.status.idle": "2022-05-04T18:11:12.376973Z",
          "shell.execute_reply": "2022-05-04T18:11:12.376546Z"
        },
        "id": "8615b722"
      },
      "outputs": [],
      "source": [
        "preprocessor = PandasDataPreprocessor(\n",
        "    col_id='client_id',\n",
        "    col_event_time='TRDATETIME',\n",
        "    event_time_transformation='dt_to_timestamp',\n",
        "    cols_category=['small_group'],\n",
        "    cols_numerical=['amount_rur_bin'],\n",
        "    return_records=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca72f6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:12.380482Z",
          "iopub.status.busy": "2022-05-04T18:11:12.380011Z",
          "iopub.status.idle": "2022-05-04T18:12:29.766372Z",
          "shell.execute_reply": "2022-05-04T18:12:29.766793Z"
        },
        "id": "fca72f6e",
        "outputId": "725b7379-aa49-4fc5-8a41-ca8979888ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 45.5 s\n",
            "Wall time: 48.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "dataset = preprocessor.fit_transform(source_data[['client_id', 'TRDATETIME', 'small_group', 'amount_rur_bin']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4ca12d",
      "metadata": {
        "id": "0e4ca12d"
      },
      "outputs": [],
      "source": [
        "dataset = sorted(dataset, key=lambda x: x['client_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e7d39d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:12:29.770820Z",
          "iopub.status.busy": "2022-05-04T18:12:29.770330Z",
          "iopub.status.idle": "2022-05-04T18:12:30.164858Z",
          "shell.execute_reply": "2022-05-04T18:12:30.165297Z"
        },
        "id": "98e7d39d",
        "outputId": "85da48c1-2992-4a08-e89e-68dda424f8d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24000, 3000, 3000)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train, valid_test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "valid, test = train_test_split(valid_test, test_size=0.5, random_state=42)\n",
        "len(train), len(valid), len(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a38930",
      "metadata": {
        "id": "e6a38930"
      },
      "source": [
        "### Naive pop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "952226f7",
      "metadata": {
        "id": "952226f7",
        "outputId": "51258551-f014-42a2-d440-26f735a2ec2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.14399694748874114"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "train_clients = [d[\"client_id\"] for d in train]\n",
        "test_clients = [d[\"client_id\"] for d in test]\n",
        "\n",
        "train_data = source_data[source_data[\"client_id\"].isin(train_clients)]\n",
        "test_data = source_data[source_data[\"client_id\"].isin(test_clients)]\n",
        "\n",
        "most_pop_mcc = train_data[\"small_group\"].value_counts().index[0]\n",
        "\n",
        "y_true = test_data[\"small_group\"]\n",
        "y_pred = [most_pop_mcc]*test_data.shape[0]\n",
        "\n",
        "f1_score(y_true, y_pred, average=\"weighted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8d0729",
      "metadata": {
        "id": "ee8d0729"
      },
      "source": [
        "### Naive prev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3043b261",
      "metadata": {
        "id": "3043b261",
        "outputId": "23d40f13-5eeb-47f5-bb54-19bc23fa0320"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1435815579218012"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = test_data.groupby(\"client_id\").apply(lambda x: x[\"small_group\"]).reset_index()[\"small_group\"].rename(\"y_true\")\n",
        "y_pred = test_data.groupby(\"client_id\").apply(lambda x: x[\"small_group\"].shift()).reset_index()[\"small_group\"].rename(\"y_pred\")\n",
        "\n",
        "y_concat = pd.concat([y_true, y_pred], axis=1).dropna()\n",
        "\n",
        "f1_score(y_concat[\"y_true\"], y_concat[\"y_pred\"], average=\"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af110e1",
      "metadata": {
        "id": "5af110e1"
      },
      "outputs": [],
      "source": [
        "train_dl = PtlsDataModule(\n",
        "    train_data=GptDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=train,\n",
        "        ),\n",
        "        min_len=25,\n",
        "        max_len=200\n",
        "    ),\n",
        "    valid_data=MlmNoSliceDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=valid,\n",
        "        ),\n",
        "    ),\n",
        "    test_data=MlmNoSliceDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=test,\n",
        "        ),\n",
        "    ),\n",
        "    train_batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d60b1033",
      "metadata": {
        "id": "d60b1033"
      },
      "source": [
        "# No pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71bf247c",
      "metadata": {
        "id": "71bf247c"
      },
      "outputs": [],
      "source": [
        "for _ in range(50):\n",
        "    trx_encoder_params = dict(\n",
        "        embeddings_noise=0.0,\n",
        "        embeddings={\n",
        "            'small_group': {'in': 203, 'out': 16},\n",
        "            'amount_rur_bin':{'in': 11, 'out': 16}\n",
        "        },\n",
        "        linear_projection_size = 32\n",
        "    )\n",
        "\n",
        "    seq_encoder = RnnEncoder(\n",
        "            input_size=32,\n",
        "            hidden_size=32,\n",
        "            type='gru',\n",
        "    )\n",
        "\n",
        "    model_downstream = NextItemPredictionModule(\n",
        "        trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "        seq_encoder=seq_encoder,\n",
        "        target_col='small_group',\n",
        "        max_lr=0.01,\n",
        "        total_steps=10000\n",
        "    )\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=50,\n",
        "        gpus=1 if torch.cuda.is_available() else 0,\n",
        "        callbacks=[pl.callbacks.EarlyStopping('gpt/valid_gpt_loss', mode='min', patience=5)],\n",
        "        enable_progress_bar=False,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model_downstream, train_dl)\n",
        "\n",
        "    data = {\n",
        "        \"Scores\": [trainer.test(model_downstream, train_dl)[0]['gpt/test_f1_weighted']]\n",
        "        }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if not os.path.isfile('results/stats_basic_sber.csv'):\n",
        "\n",
        "\n",
        "        df.to_csv('results/stats_basic_sber.csv', index = False)\n",
        "\n",
        "    else:\n",
        "\n",
        "        stats = pd.read_csv('results/stats_basic_sber.csv')\n",
        "\n",
        "        stats = pd.concat([stats, df], ignore_index=True)\n",
        "\n",
        "        stats.to_csv('results/stats_basic_sber.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9080a6f",
      "metadata": {
        "id": "f9080a6f"
      },
      "source": [
        "## Embedding training (representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56493c0b",
      "metadata": {
        "id": "56493c0b"
      },
      "source": [
        "Model training in our framework organised via pytorch-lightning (pl) framework.\n",
        "The key parts of neural networks training in pl are:\n",
        "\n",
        "    * model (`pytorch_lightning.LightningModule`)\n",
        "    * data loader (`torch.utils.data.DataLoader`)\n",
        "    * trainer (`pytorch_lightning.Trainer`)\n",
        "    \n",
        "For futher details check https://pytorchlightning.ai/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mly1BWDITvF-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mly1BWDITvF-",
        "outputId": "0b640b0e-d5d3-499b-e822-740f5d2af498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique MCC codes: 202\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of unique MCC codes:\", source_data['small_group'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f46c36",
      "metadata": {
        "id": "b9f46c36"
      },
      "outputs": [],
      "source": [
        "for _ in range(50):\n",
        "\n",
        "    trx_encoder_params = dict(\n",
        "        embeddings_noise=0.0,\n",
        "        embeddings={\n",
        "            'small_group': {'in': 203, 'out': 16},\n",
        "            'amount_rur_bin':{'in': 11, 'out': 16}\n",
        "        },\n",
        "        linear_projection_size = 32\n",
        "    )\n",
        "\n",
        "    seq_encoder = RnnEncoder(\n",
        "            input_size=32,\n",
        "            hidden_size=32,\n",
        "            type='gru',\n",
        "    )\n",
        "\n",
        "    model = GptPretrainModule(\n",
        "        trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "        seq_encoder=seq_encoder,\n",
        "        max_lr=0.1,\n",
        "        total_steps=10000\n",
        "    )\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=50,\n",
        "        gpus=1 if torch.cuda.is_available() else 0,\n",
        "        callbacks=[pl.callbacks.EarlyStopping('gpt/valid_gpt_loss', patience = 5)],\n",
        "        enable_progress_bar=False,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, train_dl)\n",
        "\n",
        "    model.trx_encoder.requires_grad_(False)\n",
        "\n",
        "    model_downstream = NextItemPredictionModule(\n",
        "        trx_encoder=model.trx_encoder, # model.trx_encoder,\n",
        "        seq_encoder=seq_encoder, # model._seq_encoder,\n",
        "        target_col='small_group',\n",
        "        max_lr=0.01,\n",
        "        total_steps=10000\n",
        "    )\n",
        "\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=50,\n",
        "        gpus=1 if torch.cuda.is_available() else 0,\n",
        "        callbacks=[pl.callbacks.EarlyStopping('gpt/valid_gpt_loss', patience=5, mode='min')],\n",
        "        enable_progress_bar=False,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model_downstream, train_dl)\n",
        "\n",
        "    data = {\n",
        "        \"Scores\": [trainer.test(model_downstream, train_dl)[0]['gpt/test_f1_weighted']]\n",
        "        }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if not os.path.isfile('results/stats_repr_sber.csv'):\n",
        "\n",
        "\n",
        "        df.to_csv('results/stats_repr_sber.csv', index = False)\n",
        "\n",
        "    else:\n",
        "\n",
        "        stats = pd.read_csv('results/stats_repr_sber.csv')\n",
        "\n",
        "        stats = pd.concat([stats, df], ignore_index=True)\n",
        "\n",
        "        stats.to_csv('results/stats_repr_sber.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6770843d",
      "metadata": {
        "id": "6770843d"
      },
      "source": [
        "# Contrastive experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "683819df",
      "metadata": {
        "id": "683819df"
      },
      "outputs": [],
      "source": [
        "for _ in range(50):\n",
        "    trx_encoder_params = dict(\n",
        "        embeddings_noise=0.0,\n",
        "        embeddings={\n",
        "            'small_group': {'in': 203, 'out': 16},\n",
        "            'amount_rur_bin':{'in': 11, 'out': 16}\n",
        "        },\n",
        "        linear_projection_size = 32\n",
        "    )\n",
        "\n",
        "    seq_encoder = RnnEncoder(\n",
        "            input_size=32,\n",
        "            hidden_size=32,\n",
        "            type='gru',\n",
        "    )\n",
        "\n",
        "    model = GptPretrainContrastiveModule(\n",
        "        trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "        seq_encoder=seq_encoder,\n",
        "        max_lr=0.1,\n",
        "        total_steps=10000,\n",
        "        neg_count=10,\n",
        "        loss_temperature=10\n",
        "    )\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=50,\n",
        "        gpus=1 if torch.cuda.is_available() else 0,\n",
        "        callbacks=[pl.callbacks.EarlyStopping('mlm/valid_mlm_loss')],\n",
        "        enable_progress_bar=False,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, train_dl)\n",
        "\n",
        "    model.trx_encoder.requires_grad_(False)\n",
        "\n",
        "    model_downstream = NextItemPredictionModule(\n",
        "        trx_encoder=model.trx_encoder, #TrxEncoder(**trx_encoder_params),\n",
        "        seq_encoder=seq_encoder, # seq_encoder,\n",
        "        target_col='small_group',\n",
        "        max_lr=0.01,\n",
        "        total_steps=10000\n",
        "    )\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=50,\n",
        "        gpus=1 if torch.cuda.is_available() else 0,\n",
        "        callbacks=[pl.callbacks.EarlyStopping('gpt/valid_gpt_loss', mode='min', patience=5)],\n",
        "        enable_progress_bar=False,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model_downstream, train_dl)\n",
        "\n",
        "    data = {\n",
        "        \"Scores\": [trainer.test(model_downstream, train_dl)[0]['gpt/test_f1_weighted']]\n",
        "        }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if not os.path.isfile('results/stats_contr_sber.csv'):\n",
        "\n",
        "\n",
        "        df.to_csv('results/stats_contr_sber.csv', index = False)\n",
        "\n",
        "    else:\n",
        "\n",
        "        stats = pd.read_csv('results/stats_contr_sber.csv')\n",
        "\n",
        "        stats = pd.concat([stats, df], ignore_index=True)\n",
        "\n",
        "        stats.to_csv('results/stats_contr_sber.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}